{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1 align=center>Capítulo 2 - Operações principais com spaCy</h1>\n",
    "<p align=center><img src=https://www.edivaldobrito.com.br/wp-content/uploads/2021/02/spacy-uma-biblioteca-de-processamento-de-linguagem-natural.jpg width=500></p>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Neste capítulo, você aprenderá as principais operações com **spaCy**, como criar um pipeline de linguagem, tokenizar o texto e dividir o texto em frases.\n",
    "\n",
    "Primeiro, você aprenderá o que é um pipeline de processamento de linguagem e os componentes do pipeline. Continuaremos com as convenções gerais de spaCy – aulas importantes e organização de classes – para ajudá-lo a entender melhor a organização da biblioteca spaCy e desenvolver uma compreensão sólida da própria biblioteca.\n",
    "\n",
    "Você aprenderá então sobre o primeiro componente do pipeline – **Tokenizer**. Você também aprenderá sobre um importante conceito linguístico – **lematização** – juntamente com suas aplicações na **compreensão da linguagem natural (NLU)**.\n",
    "\n",
    "Em seguida, abordaremos as **classes de contêiner** e as **estruturas de dados spaCy** em detalhes. Terminaremos o capítulo com recursos úteis que você usará no desenvolvimento diário de PNL.\n",
    "\n",
    "## Visão geral das convenções spaCy\n",
    "Cada aplicação de PNL consiste em várias etapas de processamento do texto. Como você pode ver no primeiro capítulo, sempre criamos instâncias chamadas **nlp** e **doc*. Mas o que fizemos exatamente?\n",
    "\n",
    "Quando chamamos **nlp** em nosso texto, **spaCy** aplica algumas etapas de processamento. A primeira etapa é a tokenização para produzir um objeto **Doc**. O objeto **Doc** é então processado com um **tagger**, um **analisador (parser)** e um **reconhecedor de entidade (entity recognizer)**. Essa maneira de processar o texto é chamada de **pipeline de processamento de linguagem**. Cada componente da pipeline retorna o **Doc** processado e o passa para o próximo componente:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src='images/pipeline_tokenizer.PNG' width=900>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Um objeto de **pipeline spaCy** é criado quando carregamos um modelo de linguagem. Carregamos um modelo em inglês e inicializamos um pipeline no seguinte segmento de código:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "doc = nlp('I went there')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "O que aconteceu exatamente no código anterior é o seguinte:\n",
    "1. Começamos importando **spaCy**.\n",
    "2. Na segunda linha, **spacy.load()** retornou uma instância da classe **Language**, **nlp**. A classe **Language** é o *pipeline de processamento de texto*.\n",
    "3. Depois disso, aplicamos **nlp** na frase de exemplo **\"I went there\"** e peguei uma instância da classe **Doc**, **doc**.\n",
    "\n",
    "A classe **Language** aplica todas as etapas anteriores do pipeline à sua frase de entrada nos bastidores. Depois de aplicar **nlp** à sentença, o objeto **Doc** contém tokens que são marcados, lematizados e marcados como entidades se o token for uma entidade (então entraremos em detalhes sobre o que são e como isso é feito posteriormente). Cada componente do pipeline tem uma tarefa bem definida:\n",
    "\n",
    "<img src=\"images/pipeline_components.PNG\" width=900>\n",
    "\n",
    "O pipeline de processamento de linguagem **spaCy** sempre depende do modelo estatístico e de seus recursos. É por isso que sempre carregamos um modelo de linguagem com **spacy.load()** como o primeiro passo em nosso código.\n",
    "\n",
    "Cada componente corresponde a uma classe **spaCy**. As classes **spaCy** têm nomes autoexplicativos, como **Language**, **Doc** e **Vocab**. Já usamos as classes **Language** e **Doc** – vamos ver todas as classes do pipeline de processamento e suas funções:\n",
    "\n",
    "<img src=\"images/processing_pipeline.png\">\n",
    "\n",
    "Não fique intimidade com o número de classes. Cada classe tem um característica única para nos ajudar a processar o texto melhor.\n",
    "\n",
    "Existem mais estruturas de dados para representar os dados de texto e os dados da linguagem. A classe Conteiner como a Doc armazena as informações sobre as sentenças, palavras e o texto. Existem outras classes conteiner além da Doc:\n",
    "\n",
    "<img src=\"images/conteiner_classes.PNG\" width=900>\n",
    "\n",
    "Finalmente, spaCy fornece classes auxiliares para vetores, vocabulário de linguagem e anotações. Veremos a classe **Vocab** frequentemente neste livro. **Vocab** representa o vocabulário de uma língua. Vocab contém todas as palavras do modelo de linguagem que carregamos:\n",
    "\n",
    "<img src=\"images/outras_classes.PNG\" width=900>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As estruturas de dados do backbone da biblioteca spaCy são **Doc** e **Vocab**. O objeto **Doc** abstrai o texto possuindo a sequência de tokens e todas as suas propriedades. O objeto **Vocab** fornece um conjunto centralizado de **strings** e atributos léxicos para todas as outras classes. Dessa forma, o **spaCy** evita o armazenamento de várias cópias de dados linguísticos:\n",
    "\n",
    "<img src=\"images/diagrama_spacy.PNG\">\n",
    "\n",
    "Você pode dividir os objetos que compõem a arquitetura spaCy anterior em dois: **contêineres** e **componentes de pipeline de processamento**. Neste capítulo, primeiro aprenderemos sobre dois componentes básicos, **Tokenizer** e **Lemmatizer**, depois exploraremos mais os objetos **Container**.\n",
    "\n",
    "**spaCy** faz todas essas operações para nós nos bastidores, permitindo que nos concentremos no desenvolvimento de nosso próprio aplicativo. Com esse nível de abstração, usar **spaCy** para desenvolvimento de aplicativos NLP não é coincidência. Vamos começar com a classe **Tokenizer** e ver o que ela oferece para nós; em seguida, exploraremos todas as classes de contêineres uma a uma ao longo do capítulo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
