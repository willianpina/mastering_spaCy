{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Capítulo 10: Juntando tudo: projetando seu chatbot com spaCy\n",
    "Neste capítulo, você usará tudo o que aprendeu até agora para projetar um chatbot. Você realizará extração de entidade, reconhecimento de intenção e manipulação de contexto. Você usará diferentes formas de análise sintática e semântica, extração de entidade e classificação de texto. Primeiro, você explorará o conjunto de dados que usaremos para coletar informações linguísticas sobre os enunciados nele. Em seguida, você executará a extração de entidade combinando o modelo spaCy de reconhecimento de entidade nomeada (NER) e a classe spaCy Matcher. Depois disso, você realizará o reconhecimento de intenção com duas técnicas diferentes: um método baseado em padrões e classificação estatística de texto com TensorFlow e Keras. Você treinará um LSTM em nível de caractere para classificar as intenções de expressão. A seção final é uma seção dedicada à semântica em nível de sentença e diálogo. Você mergulhará profundamente em assuntos semânticos, como resolução de anáforas, tipos de perguntas gramaticais e diferenciação de assuntos de objetos. No final deste capítulo, você estará pronto para projetar um pipeline de entendimento de linguagem natural (NLU) de chatbot real. Você reunirá o que aprendeu em todos os capítulos anteriores – linguística e estatisticamente – combinando vários componentes de pipeline spaCy, como NER, um analisador de dependência e um tagger POS. Neste capítulo, abordaremos os seguintes tópicos principais: Introdução à extração de entidade de IA conversacional Reconhecimento de intenção"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Introdução à IA conversacional\n",
    "Sejam bem-vindos ao nosso último e muito empolgante capítulo, onde você projetará um pipeline NLU de chatbot com spaCy e TensorFlow. Neste capítulo, você aprenderá as técnicas NLU para extrair significado das interações multiturno do chatbot-usuário. Ao aprender e aplicar essas técnicas, você dará um passo no desenvolvimento de IA conversacional. Antes de mergulhar nos detalhes técnicos, há uma pergunta fundamental: o que é um chatbot? Onde podemos encontrar um? O que exatamente significa IA conversacional? A inteligência artificial conversacional (IA conversacional) é um campo de aprendizado de máquina que visa criar tecnologia que permita que os usuários tenham interações baseadas em texto ou fala com máquinas. Chatbots, assistentes virtuais e assistentes de voz são produtos típicos de IA conversacional. Um chatbot é um aplicativo de software projetado para fazer conversas com humanos em aplicativos de bate-papo. Os chatbots são populares em uma ampla variedade de áreas comerciais, incluindo RH, marketing e vendas, bancos e saúde, bem como em áreas pessoais e não comerciais, como conversa fiada. Muitas empresas comerciais, como a Sephora (a Sephora possui dois chatbots – um chatbot de maquiador virtual na plataforma de mensagens do Facebook e um chatbot de atendimento ao cliente novamente no Facebook Messenger), IKEA (a IKEA tem um chatbot de atendimento ao cliente chamado Anna), AccuWeather e muitos mais, atendimento ao cliente próprio e chatbots de perguntas frequentes. Os serviços de mensagens instantâneas, como o Facebook Messenger e o Telegram, fornecem interfaces para os desenvolvedores conectarem seus bots. Essas plataformas também fornecem diretrizes detalhadas para desenvolvedores, como a documentação da API do Facebook Messenger: (https://developers.facebook.com/docs/messenger-platform/getting-start/quick-start/) ou a documentação da API do bot do Telegram : (https://core.telegram.org/bots). Um assistente virtual também é um agente de software que executa algumas tarefas mediante solicitação ou pergunta do usuário. Um exemplo bem conhecido é o Amazon Alexa. Alexa é um assistente virtual baseado em voz e pode executar muitas tarefas, incluindo tocar música, definir alarmes, ler audiolivros, reproduzir podcasts e fornecer informações em tempo real sobre clima, trânsito, esportes e assim por diante. O Alexa Home pode controlar dispositivos domésticos inteligentes conectados e executar uma variedade de tarefas, incluindo acender e apagar as luzes, controlar a porta da garagem e assim por diante. Outros exemplos conhecidos são Google Assistant e Siri. A Siri está integrada em vários produtos da Apple, incluindo iPhone, iPad, iPod e macOS. No iPhone, a Siri pode fazer chamadas, atender chamadas e enviar e receber mensagens de texto, bem como mensagens do WhatsApp. O Google Assistant também pode executar uma ampla variedade de tarefas, como fornecer informações de voo, clima e tráfego em tempo real; enviar e receber mensagens de texto; configuração de alarmes; Fornecimento de informações sobre a bateria do dispositivo; verificar sua caixa de entrada de e-mail; integração com dispositivos domésticos inteligentes; e assim por diante. O Google Assistant está disponível no Google Maps, na Pesquisa Google e em aplicativos autônomos para Android e iOS. Aqui está uma lista dos assistentes virtuais mais populares e conhecidos para lhe dar mais algumas idéias do que está por aí: Amazon Alexa AllGenie do Alibaba Group Bixby da Samsung Celia da Huawei Duer do Baidu Google Assistant Microsoft Cortana Siri da Apple Xiaowei da Tencent Todos esses assistentes virtuais são baseados em voz e geralmente são invocados com uma palavra de ativação. Uma palavra de ativação é uma palavra ou frase especial usada para ativar um assistente de voz. Alguns exemplos são Hey Alexa, Hey Google e Hey Siri, que são as palavras de ativação do Amazon Alexa, Google Assistant e Siri, respectivamente. Se você quiser saber mais sobre os detalhes de desenvolvimento desses produtos, consulte a seção Referências deste capítulo. Agora vamos aos detalhes técnicos. Quais são os componentes de PNL desses produtos? Vejamos esses componentes da PNL em detalhes. Componentes de PNL de produtos de IA conversacional Um produto típico de IA conversacional baseado em voz consiste nos seguintes componentes: Componente de fala para texto: converte a fala do usuário em texto. A entrada para este componente é um arquivo WAV/mp3 e a saída é um arquivo de texto contendo o enunciado do usuário como texto. Componente NLU Conversacional: Este componente realiza reconhecimento de intenção e extração de entidade no texto do enunciado do usuário. A saída é a intenção do usuário e uma lista de entidades. A resolução de referências no enunciado atual para os enunciados anteriores é feita neste componente (consulte a seção Resolução de anáfora). Gerenciador de diálogo: Mantém a memória da conversa para fazer um bate-papo significativo e coerente. Você pode pensar nesse componente como a memória de diálogo, pois esse componente geralmente mantém um estado de diálogo. O estado do diálogo é o estado da conversa: as entidades que apareceram até agora, as intenções que apareceram até agora e assim por diante. A entrada para este componente é o estado de diálogo anterior e o usuário atual analisado com intenção e entidades. A saída deste componente é o novo estado de diálogo. Gerador de respostas: Dadas todas as entradas das etapas anteriores, gera a resposta do sistema ao enunciado do usuário. Text-to-speech: Este componente gera um arquivo de fala (WAV ou mp3) a partir da resposta do sistema. Cada um dos componentes é treinado e avaliado separadamente. Por exemplo, o componente de fala para texto é treinado em um corpus de fala anotado (o treinamento é feito em arquivos de fala e as transcrições correspondentes). O componente NLU é treinado na intenção e em uma entidade rotulada como corpus (semelhante aos conjuntos de dados que usamos nos Capítulos 6, 7, 8 e 9). Neste capítulo, vamos nos concentrar nas tarefas do componente NLU. Para produtos baseados em texto, o primeiro e o último componentes não são necessários e são substituídos pela integração do cliente de e-mail ou chat. Há outro paradigma que é chamado de compreensão da linguagem falada de ponta a ponta (SLU). Nas arquiteturas SLU, o sistema é treinado de ponta a ponta, o que significa que a entrada do sistema é um arquivo de fala e a saída é a resposta do sistema. Cada abordagem tem prós e contras; você pode consultar a seção Referências para obter mais material. Como autor deste livro, tenho o prazer de apresentar este capítulo a você com minha experiência de domínio. Trabalho na área de IA de conversação há algum tempo e enfrento desafios de processamento de linguagem e fala todos os dias para nosso produto. Eu e meus colegas estamos construindo o primeiro assistente digital de motorista do mundo, Chris (Dicas e Truques: Como falar com Chris – comandos básicos de voz, https://www.youtube.com/watch?v=Qwnjszu3exY). Chris pode fazer chamadas, atender chamadas recebidas, ler e escrever WhatsApp e mensagens de texto, tocar música, navegar e conversar. Aqui está Cris:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como vemos nos exemplos anteriores, a IA conversacional tornou-se um tema quente recentemente. Como profissional de PNL, é bem provável que você trabalhe para um produto de conversação ou trabalhe em uma área relacionada, como reconhecimento de fala, conversão de texto em fala ou resposta a perguntas. As técnicas apresentadas neste capítulo, como reconhecimento de intenção, extração de entidade e resolução de anáfora, também são aplicáveis a um amplo conjunto de problemas de NLU. Vamos mergulhar nas seções técnicas. Começaremos explorando o conjunto de dados que usaremos ao longo deste capítulo. Conhecendo o conjunto de dados Nos Capítulos 6, 7, 8 e 9, trabalhamos em conjuntos de dados bem conhecidos do mundo real para fins de classificação de texto e extração de entidades. Nestes capítulos, sempre exploramos nosso conjunto de dados como a primeira tarefa. O ponto principal da exploração de dados é entender a natureza do texto do conjunto de dados para desenvolver estratégias em nossos algoritmos que possam lidar com esse conjunto de dados. Se nos lembrarmos do Capítulo 6, Juntando tudo: análise semântica com espaço, os pontos principais que devemos observar durante nossa exploração são os seguintes: Que tipo de enunciados existem? Os enunciados são textos curtos ou frases completas ou parágrafos ou documentos longos? Qual é a duração média do enunciado? Que tipo de entidades o corpus inclui? Nomes de pessoas, nomes de organizações, localizações geográficas, nomes de ruas? Quais queremos extrair? Como a pontuação é usada? O texto está pontuado corretamente ou nenhuma pontuação é usada? Como as regras gramaticais são seguidas? A capitalização está correta e os usuários seguiram as regras gramaticais? Existem palavras incorretas? Os conjuntos de dados anteriores que usamos consistiam em pares (texto, class_label) a serem usados em tarefas de classificação de texto ou (texto, list_of_entities) pares a serem usados em tarefas de extração de entidade. Neste capítulo, abordaremos uma tarefa muito mais complicada, o design do chatbot. Assim, o conjunto de dados será mais estruturado e mais complicado. Os conjuntos de dados de design do chatbot geralmente estão no formato JSON para manter a estrutura do conjunto de dados. Aqui, estrutura significa o seguinte: Manter a ordem dos enunciados do usuário e do sistema Marcar slots dos enunciados do usuário Rotular a intenção dos enunciados do usuário Ao longo deste capítulo, usaremos o conjunto de dados The Schema-Guided Dialogue (SGD) do Google Research (https: //github.com/google-research-datasets/dstc8-schema-guided-dialogue). Esse conjunto de dados consiste em interações anotadas do assistente virtual do usuário. O conjunto de dados original contém mais de 20.000 segmentos de diálogo em diversas áreas, incluindo reservas de restaurantes, reservas de filmes, consultas meteorológicas e reservas de passagens. Os diálogos incluem enunciados do usuário e do assistente virtual turno a turno. Neste capítulo, não usaremos todo esse enorme conjunto de dados; em vez disso, usaremos um subconjunto sobre reservas em restaurantes. Vamos começar com o download do conjunto de dados. Você pode baixar o conjunto de dados do repositório GitHub do livro em https://github.com/PacktPublishing/Mastering- spaCy/blob/main/Chapter10/data/restaurants.json. Alternativamente, você pode escrever o seguinte código:"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
